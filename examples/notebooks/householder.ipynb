{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from survae.transforms.bijections.functional.householder import householder_matrix, householder_matrix_fast\n",
    "from survae.transforms.bijections.linear_orthogonal import LinearHouseholder, LinearOrthogonal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_orthogonal(Q):\n",
    "    \n",
    "    I = torch.eye(Q.shape[0])\n",
    "    torch.testing.assert_close(I, Q.T @ Q) \n",
    "    torch.testing.assert_close(I, Q @ Q.T) \n",
    "    torch.testing.assert_close(Q.inverse(), Q.t(), rtol=1e-3, atol=1e-3)\n",
    "    torch.testing.assert_close(torch.linalg.slogdet(Q)[1], torch.zeros(()), rtol=1e-3, atol=1e-3)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 1000\n",
    "num_reflections = 10\n",
    "\n",
    "# random iniitialization (for fixed)\n",
    "vs = torch.randn(num_reflections, num_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**: [nflows]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dimensions = 1000\n",
    "num_reflections = 10\n",
    "\n",
    "# random iniitialization (for fixed)\n",
    "vs = torch.randn(num_reflections, num_dimensions)\n",
    "\n",
    "Q = householder_matrix(vs, loop=True)\n",
    "\n",
    "test_orthogonal(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**: [Invert to Invert]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_bmm = householder_matrix(vs, loop=False)\n",
    "# check shape\n",
    "assert Q_bmm.shape[0] == vs.shape[1]\n",
    "# check orthogonality\n",
    "torch.testing.assert_close(Q, Q_bmm)\n",
    "test_orthogonal(Q_bmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**: [Fast Householder Matrix]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 2\n",
    "Q_fast = householder_matrix_fast(vs, stride)\n",
    "\n",
    "test_orthogonal(Q_fast)\n",
    "torch.testing.assert_close(Q, Q_fast)\n",
    "torch.testing.assert_close(Q_bmm, Q_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit Q = householder_matrix(vs, loop=True)\n",
    "# %timeit Q_bmm = householder_matrix(vs, loop=False)\n",
    "# %timeit Q_fast = householder_matrix_fast(vs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import itertools\n",
    "\n",
    "# num_features = [2, 10, 50, 100, 1_000, \n",
    "#                 10_000, 100_000\n",
    "#                ]\n",
    "# num_reflections = [\n",
    "#     2, 2, 5, 10, 50, 50, 100\n",
    "# ]\n",
    "\n",
    "\n",
    "# methods = [\n",
    "#     \"matrix\", \n",
    "#     \"loops\",\n",
    "#     \"fast\", \n",
    "#     # \"base\"\n",
    "#           ]\n",
    "# results = {imethod: list() for imethod in methods}\n",
    "\n",
    "# def run_method(num_dims, num_hh, method: str):\n",
    "    \n",
    "#     # random iniitialization (for fixed)\n",
    "#     vs = torch.randn(num_hh, num_dims)\n",
    "    \n",
    "#     if method == \"loops\":\n",
    "#         res = %timeit -n10 -r10 -o construct_householder_matrix(vs, loop=True)\n",
    "#         return res\n",
    "#     elif method == \"matrix\":\n",
    "#         res = %timeit -n10 -r10 -o construct_householder_matrix(vs, loop=False)\n",
    "#         return res\n",
    "#     elif method == \"fast\":\n",
    "#         res = %timeit -n10 -r10 -o fast_householder_matrix(vs, 2)\n",
    "#         return res\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unrecognized method: {method}\")\n",
    "\n",
    "# for ifeatures, ireflections in tqdm(zip(num_features, num_reflections)):\n",
    "    \n",
    "#     # benchmarks\n",
    "#     for imethod in tqdm(methods):\n",
    "        \n",
    "#         ires = run_method(ifeatures, ireflections, imethod)\n",
    "        \n",
    "#         # extract infor\n",
    "#         results[imethod].append((ires.average, ires.stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 32\n",
    "num_features = 10\n",
    "num_reflections = 2\n",
    "\n",
    "X = torch.randn(32, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lin_hh = LinearHouseholder(\n",
    "    num_features=num_features, num_reflections=num_reflections, \n",
    "    fixed=True\n",
    ")\n",
    "\n",
    "Z, ldj = lin_hh(X)\n",
    "\n",
    "# check shape\n",
    "assert Z.shape == X.shape\n",
    "\n",
    "\n",
    "X_approx = lin_hh.inverse(Z)\n",
    "\n",
    "# check inverse\n",
    "torch.testing.assert_close(X, X_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lin_hh = LinearHouseholder(\n",
    "    num_features=num_features, num_reflections=num_reflections, \n",
    "    fixed=False, fast=False, loop=True\n",
    ")\n",
    "\n",
    "Z, ldj = lin_hh(X)\n",
    "\n",
    "# check shape\n",
    "assert Z.shape == X.shape\n",
    "\n",
    "\n",
    "X_approx = lin_hh.inverse(Z)\n",
    "\n",
    "# check inverse\n",
    "torch.testing.assert_close(X, X_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_hh_mat = LinearHouseholder(\n",
    "    num_features=num_features, num_reflections=num_reflections, \n",
    "    fixed=False, fast=False, loop=False\n",
    ")\n",
    "\n",
    "Z, ldj = lin_hh_mat.forward(X)\n",
    "\n",
    "# check shape\n",
    "assert Z.shape == X.shape\n",
    "\n",
    "\n",
    "X_approx = lin_hh_mat.inverse(Z)\n",
    "\n",
    "# check inverse\n",
    "torch.testing.assert_close(X, X_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_hh_fast = LinearHouseholder(\n",
    "    num_features=num_features, num_reflections=num_reflections, \n",
    "    fixed=False, fast=True, loop=False\n",
    ")\n",
    "\n",
    "Z, ldj = lin_hh_fast.forward(X)\n",
    "\n",
    "# check shape\n",
    "assert Z.shape == X.shape\n",
    "\n",
    "\n",
    "X_approx = lin_hh_fast.inverse(Z)\n",
    "\n",
    "# check inverse\n",
    "torch.testing.assert_close(X, X_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 100\n",
    "num_reflections = 10\n",
    "\n",
    "# random iniitialization (for fixed)\n",
    "vs = torch.randn(num_reflections, num_dimensions)\n",
    "\n",
    "V_t = vs.unsqueeze(2).transpose(1, 2)\n",
    "V = vs.unsqueeze(2)\n",
    "I = torch.eye(n_dimensions, dtype=vs.dtype, device=vs.device)\n",
    "\n",
    "U = I - 2 * torch.bmm(V, V_t) / torch.bmm(V_t, V)\n",
    "Q = torch.chain_matmul(*U)\n",
    "Q_ = torch.linalg.multi_dot(tuple(U))\n",
    "\n",
    "torch.testing.assert_close(Q, Q_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        V = self.weights\n",
    "        V_t = self.weights.transpose(1, 2)\n",
    "        U = self.I - 2 * torch.bmm(V, V_t) / torch.bmm(V_t, V)\n",
    "        W = torch.chain_matmul(*U)\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n",
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "num_dims = 100\n",
    "num_reflections = 10\n",
    "\n",
    "# random iniitialization (for fixed)\n",
    "vs = torch.randn(num_dims, num_reflections)\n",
    "vs = vs.transpose(-1, -2)\n",
    "print(vs.shape)\n",
    "# close to ideneity\n",
    "vs = torch.eye(num_dims, num_reflections)\n",
    "vs += torch.randn_like(vs) * 0.1\n",
    "vs = vs.transpose(-1, -2)\n",
    "print(vs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_fast = fast_householder_matrix(vs, 10)\n",
    "Q = construct_householder_matrix(vs)\n",
    "\n",
    "torch.testing.assert_close(Q, Q_fast)\n",
    "Q_fast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_features = [2, 10, 50, 100, 1_000, \n",
    "                10_000, 100_000\n",
    "               ]\n",
    "methods = [\n",
    "    # \"householder\", \n",
    "    \"cayley\",\n",
    "    # \"matrix_exp\", \n",
    "    # \"base\"\n",
    "          ]\n",
    "results = {imethod: list() for imethod in methods}\n",
    "\n",
    "def run_method(num_dims, method: str):\n",
    "    \n",
    "    X = torch.randn((batch_size, num_dims))\n",
    "    \n",
    "    if method == \"householder\":\n",
    "        lin = LinearOrthogonal(num_dims, norm=\"householder\")\n",
    "    elif method == \"cayley\":\n",
    "        lin = LinearOrthogonal(num_dims, norm=\"cayley\")\n",
    "    elif method == \"matrix_exp\":\n",
    "        lin = LinearOrthogonal(num_dims, norm=\"matrix_exp\")\n",
    "    elif method == \"base\":\n",
    "        lin = Linear(num_dims)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized method: {method}\")\n",
    "        \n",
    "    \n",
    "    res = %timeit -n10 -r10 -o lin.forward(X)\n",
    "    return res\n",
    "\n",
    "for ifeatures in tqdm(num_features):\n",
    "    \n",
    "    # benchmarks\n",
    "    for imethod in tqdm(methods):\n",
    "        \n",
    "        ires = run_method(ifeatures, imethod)\n",
    "        \n",
    "        # extract infor\n",
    "        results[imethod].append((ires.average, ires.stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           if self.fixed:\n",
    "                # init randomly\n",
    "                init = torch.randn(self.width, self.n_reflections)\n",
    "            else:\n",
    "                # init close to identity\n",
    "                init = torch.eye(self.width, self.n_reflections)\n",
    "                init += torch.randn_like(init) * 0.1\n",
    "            Vs = init.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_dims = 100\n",
    "    num_reflections = 10\n",
    "    strides = 2\n",
    "    v = torch.ones((num_reflections, num_dims))\n",
    "    \n",
    "    nn.init.orthogonal_(v)\n",
    "    scale = torch.sum(v ** 2, dim=-1)\n",
    "    Q = construct_householder_matrix(v)\n",
    "    Q_fast = fast_householder_matrix(v, strides)\n",
    "    \n",
    "    \n",
    "torch.testing.assert_close(Q, Q_fast)\n",
    "test_orthogonal(Q);\n",
    "test_orthogonal(Q_fast);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]),\n",
       " torch.Size([10, 2]),\n",
       " torch.Size([2]),\n",
       " torch.Size([10, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dims = 10\n",
    "num_reflections = 2\n",
    "v = torch.ones((num_dims, num_reflections))\n",
    "h, tau = torch.geqrf(v)\n",
    "\n",
    "Q_t = torch.linalg.householder_product(h, tau)\n",
    "v.shape, h.shape, tau.shape, Q_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_dims = 10\n",
    "    num_reflections = 2\n",
    "    strides = 2\n",
    "    v = torch.ones((num_reflections, num_dims))\n",
    "    \n",
    "    nn.init.orthogonal_(v)\n",
    "    scale = 2 / (v * v).sum(dim=1)\n",
    "    Q_t = torch.linalg.householder_product(v.T, scale)\n",
    "    \n",
    "\n",
    "# assert Q_t.shape == (num_dims, num_dims)\n",
    "# test_orthogonal(Q_t);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create orthogonal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_dims = 100\n",
    "X = torch.randn((batch_size, num_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survae.transforms.bijections.linear_orthogonal import LinearOrthogonal\n",
    "from survae.transforms.bijections.linear import Linear\n",
    "\n",
    "batch_size = 32\n",
    "num_dims = 50\n",
    "X = torch.randn((batch_size, num_dims))\n",
    "\n",
    "lin_ortho = LinearOrthogonal(num_dims, norm=\"matrix_exp\")\n",
    "\n",
    "Z, ldj = lin_ortho.forward(X)\n",
    "assert Z.shape == X.shape\n",
    "assert ldj.shape[0] == X.shape[0]\n",
    "\n",
    "# test_orthogonal(lin_ortho.weight)\n",
    "# test_orthogonal(lin_ortho.weight_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1 ms ± 161 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "12.1 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "4.93 ms ± 94.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "4.69 ms ± 53.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "lin_ortho = LinearOrthogonal(num_dims, norm=\"householder\")\n",
    "%timeit lin_ortho.forward(X)\n",
    "lin_ortho = LinearOrthogonal(num_dims, norm=\"cayley\")\n",
    "%timeit lin_ortho.forward(X)\n",
    "lin_ortho = LinearOrthogonal(num_dims, norm=\"matrix_exp\")\n",
    "%timeit lin_ortho.forward(X)\n",
    "lin = Linear(num_dims)\n",
    "%timeit lin.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# num_features = [2, 10, 50, 100, 1_000, \n",
    "#                 10_000, 100_000\n",
    "#                ]\n",
    "# methods = [\n",
    "#     # \"householder\", \n",
    "#     \"cayley\",\n",
    "#     # \"matrix_exp\", \n",
    "#     # \"base\"\n",
    "#           ]\n",
    "# results = {imethod: list() for imethod in methods}\n",
    "\n",
    "# def run_method(num_dims, method: str):\n",
    "    \n",
    "#     X = torch.randn((batch_size, num_dims))\n",
    "    \n",
    "#     if method == \"householder\":\n",
    "#         lin = LinearOrthogonal(num_dims, norm=\"householder\")\n",
    "#     elif method == \"cayley\":\n",
    "#         lin = LinearOrthogonal(num_dims, norm=\"cayley\")\n",
    "#     elif method == \"matrix_exp\":\n",
    "#         lin = LinearOrthogonal(num_dims, norm=\"matrix_exp\")\n",
    "#     elif method == \"base\":\n",
    "#         lin = Linear(num_dims)\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unrecognized method: {method}\")\n",
    "        \n",
    "    \n",
    "#     res = %timeit -n10 -r10 -o lin.forward(X)\n",
    "#     return res\n",
    "\n",
    "# for ifeatures in tqdm(num_features):\n",
    "    \n",
    "#     # benchmarks\n",
    "#     for imethod in tqdm(methods):\n",
    "        \n",
    "#         ires = run_method(ifeatures, imethod)\n",
    "        \n",
    "#         # extract infor\n",
    "#         results[imethod].append((ires.average, ires.stdev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "# for imethod, istats in results.items():\n",
    "    \n",
    "#     means, stdevs = zip(*istats)\n",
    "#     upper = [imean + istd for imean, istd in zip(means, stdevs)]\n",
    "    \n",
    "#     ax.plot(num_features, means, label=imethod)\n",
    "#     # ax.plot(num_features, upper)\n",
    "    \n",
    "# ax.set(\n",
    "#     xlabel=\"Features\",\n",
    "#     ylabel=\"Time (secs)\",\n",
    "#     yscale=\"log\"\n",
    "# )\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_channels = 3\n",
    "num_height = 10\n",
    "num_width = 10\n",
    "X_img = torch.randn((batch_size, n_channels, num_height, num_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_img = conv(X_img)\n",
    "Z_img_ = F.conv2d(X_img, conv.weight)\n",
    "torch.testing.assert_close(Z_img, Z_img_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### orthogonal parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(n_channels, n_channels, kernel_size=1, bias=False)\n",
    "nn.init.orthogonal_(conv.weight)\n",
    "ortho_conv = torch.nn.utils.parametrizations.orthogonal(\n",
    "    conv, \n",
    "    orthogonal_map=\"householder\" # options: \"caley\", \"householder\", \"matrix_exp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ParametrizedConv2d' object has no attribute 'kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [198]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conv\u001b[38;5;241m.\u001b[39mweight, \u001b[43mortho_conv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParametrizedConv2d' object has no attribute 'kernel'"
     ]
    }
   ],
   "source": [
    "conv.weight, ortho_conv.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_img = ortho_conv(X_img)\n",
    "Z_img_ = F.conv2d(X_img, ortho_conv.weight)\n",
    "torch.testing.assert_close(Z_img, Z_img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Module 'Parameter containing:\ntensor([[ 0.8983, -0.2604, -0.4213,  ...,  0.0279, -0.6643, -0.4095],\n        [ 0.3463,  0.7041, -0.4180,  ..., -0.2793,  0.0466, -0.7407],\n        [ 0.3860,  0.5907, -0.2380,  ..., -0.5145,  0.2181,  0.2852],\n        ...,\n        [-1.1514, -0.9348,  0.3687,  ..., -0.1956, -1.3657,  0.9945],\n        [-1.1207, -0.3512, -0.7432,  ..., -0.2833,  0.6492, -1.2670],\n        [ 0.5332, -0.0198, -0.3383,  ..., -0.3099,  0.4659, -0.8023]],\n       requires_grad=True)' has no parameter ot buffer with name 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m V \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((num_dims, num_dims))\n\u001b[1;32m      2\u001b[0m param \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(V)\n\u001b[0;32m----> 3\u001b[0m ortho_param \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparametrizations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morthogonal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_py39/lib/python3.9/site-packages/torch/nn/utils/parametrizations.py:260\u001b[0m, in \u001b[0;36morthogonal\u001b[0;34m(module, name, orthogonal_map, use_trivialization)\u001b[0m\n\u001b[1;32m    258\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight, Tensor):\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no parameter ot buffer with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(module, name)\n\u001b[1;32m    262\u001b[0m     )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# We could implement this for 1-dim tensors as the maps on the sphere\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# but I believe it'd bite more people than it'd help\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Module 'Parameter containing:\ntensor([[ 0.8983, -0.2604, -0.4213,  ...,  0.0279, -0.6643, -0.4095],\n        [ 0.3463,  0.7041, -0.4180,  ..., -0.2793,  0.0466, -0.7407],\n        [ 0.3860,  0.5907, -0.2380,  ..., -0.5145,  0.2181,  0.2852],\n        ...,\n        [-1.1514, -0.9348,  0.3687,  ..., -0.1956, -1.3657,  0.9945],\n        [-1.1207, -0.3512, -0.7432,  ..., -0.2833,  0.6492, -1.2670],\n        [ 0.5332, -0.0198, -0.3383,  ..., -0.3099,  0.4659, -0.8023]],\n       requires_grad=True)' has no parameter ot buffer with name 'weight'"
     ]
    }
   ],
   "source": [
    "V = torch.randn((num_dims, num_dims))\n",
    "param = nn.Parameter(V)\n",
    "ortho_param = torch.nn.utils.parametrizations.orthogonal(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.orthogonal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4472, 1.5000])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925 µs ± 9.43 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "413 µs ± 2.76 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit construct_householder_matrix(v)\n",
    "%timeit fast_householder_matrix(v, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = torch.eye(num_dims)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q.T @ Q).shape, (Q @ Q.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb1e36a1c7d62281da7abd3a1e41c6db9921f18def34698849cb0ad452ff6ad4"
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch_py39]",
   "language": "python",
   "name": "conda-env-torch_py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
